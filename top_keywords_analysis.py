import glob
from pyspark.sql import SparkSession, DataFrame
from pyspark.sql.functions import col, count, row_number
from pyspark.sql.window import Window

def get_top3_keywords_per_user(df: DataFrame) -> DataFrame:
    """
    Tráº£ vá» top 3 keyword Ä‘Æ°á»£c tÃ¬m nhiá»u nháº¥t cho má»—i user_id.
    """
    # Äáº¿m sá»‘ láº§n má»—i keyword Ä‘Æ°á»£c tÃ¬m bá»Ÿi tá»«ng user
    keyword_count = (
        df.groupBy("user_id", "keyword")
          .agg(count("*").alias("search_count"))
    )

    # XÃ¡c Ä‘á»‹nh top 3 tá»« khÃ³a phá»• biáº¿n nháº¥t cho tá»«ng user
    windowSpec = Window.partitionBy("user_id").orderBy(col("search_count").desc())

    top_keywords = (
        keyword_count
        .withColumn("rank", row_number().over(windowSpec))
        .filter(col("rank") <= 3)
        .select("user_id", "keyword", "search_count", "rank")
        .orderBy( col("search_count").desc())
    )

    return top_keywords


def read_all_parquet(base_path: str) -> DataFrame:
    """
    Äá»c toÃ n bá»™ file parquet trong táº¥t cáº£ thÆ° má»¥c con cá»§a base_path.
    """
    # TÃ¬m táº¥t cáº£ cÃ¡c file .parquet trong má»i folder con
    files = glob.glob(f"{base_path}/**/*.parquet", recursive=True)
    
    if not files:
        raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y file parquet trong Ä‘Æ°á»ng dáº«n: {base_path}")
    
    print(f"ğŸ”¹ TÃ¬m tháº¥y {len(files)} file parquet.")

    # Khá»Ÿi táº¡o SparkSession
    spark = SparkSession.builder.appName("TopKeywordsAnalysis").getOrCreate()

    # Äá»c táº¥t cáº£ file parquet
    df = spark.read.parquet(*files)
    return df


if __name__ == "__main__":
    base_path = r"D:\study_de\Homework\log_search_etl\log_search"

    print("ğŸš€ Äang Ä‘á»c dá»¯ liá»‡u parquet...")
    df = read_all_parquet(base_path)

    print("ğŸ“Š Schema cá»§a dá»¯ liá»‡u:")
    df.printSchema()

    print("ğŸ”¥ Äang phÃ¢n tÃ­ch top 3 keyword theo tá»«ng user_id...")
    result_df = get_top3_keywords_per_user(df)

    print("âœ… Káº¿t quáº£ top 3 keyword:")
    result_df.show(50, truncate=False)

    # Náº¿u muá»‘n lÆ°u káº¿t quáº£ láº¡i (tuá»³ chá»n)
#     result_df.write.mode("overwrite").parquet(r"D:\study_de\Homework\output\top_keywords")
